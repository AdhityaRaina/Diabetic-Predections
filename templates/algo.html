
<html>
{% load static %}
<head>

    <title>Knn analysis</title>
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css">
  <link href="https://fonts.googleapis.com/css?family=Montserrat" rel="stylesheet">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js"></script>
 <link rel="stylesheet" type="text/css" href="{% static 'classifier/plugin.css' %}">

<style type="text/css">
  .footer {
   position: fixed;
   left: 0;
   bottom: 0;
   width: 100%;
   background-color: #1abc9c;
   color: white;
   text-align: center;
   height: 44;
}
</style>
</head>
<body>
<div class="container-fluid bg-1 text-center">
  
  <div class="col-md-6">
  <img src="{% static 'classifier/img/d1.jpg' %}" id="boxshadow" style="height: 51%">
<!--<img src="{% static "classifier/img/d1.jpg" %}" alt="something" >
-->
  </div>
  <div class="col-md-6 text-center">
  <h3>Check whether the person<br> has diabetes or not??
  </h3>
  <h3>Using MACHINE LEARNING Algorithm</h3>
  <img src="{% static 'classifier/img/d2.jpg' %}"/ class="margin" id="boxshadow" width="50%" height="25%" >
  </div>
</div>


<nav class="navbar navbar-default">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#myNavbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>                        
      </button>
    </div>
    <div class="collapse navbar-collapse" id="myNavbar">
      <ul class="nav navbar-nav navbar-left">
        <li><a href="{% url 'home' %}">Home</a></li>
        <li><a href="{% url 'dataset' %}">About Dataset</a></li>
        <li><a href="{% url 'algorithm' %}">Machine Learning Algorithm</a></li>
      </ul>
    </div>
  </div>
</nav>



</div>
    </div>
    <div  class="container-fluid text-center text-justify" style="margin:50px">
      <h3>About Algorithm</h3>
<b>Introduction to K-nearest neighbor classifier</b>
<p>K-nearest neighbor classifier is one of the introductory supervised classifier, which every data science learner should be aware of. Fix & Hodges proposed K-nearest neighbor classifier algorithm in the year of 1951 for performing pattern classification task.
<br>
For simplicity, this classifier is called as Knn Classifier. To be surprised k-nearest neighbor classifier mostly represented as Knn, even in many research papers too. Knn address the pattern recognition problems and also the best choices for addressing some of the classification related tasks.
<br>
The simple version of the K-nearest neighbor classifier algorithms is to predict the target label by finding the nearest neighbor class. The closest class will be identified using the distance measures like Euclidean distance.
</p>

<b>K-nearest neighbor classification step by step procedure</b>
<p>Before diving into the k-nearest neighbor, classification process lets’s understand the application-oriented example where we can use the knn algorithm.
</p>
<b>Knn classification application</b>
<p>Let’s assume a money lending company “XYZ” like UpStart, IndiaLends, etc. Money lending XYZ company is interested in making the money lending system comfortable & safe for lenders as well as for borrowers. The company holds a database of customer’s details.
<br>
Using customer’s detailed information from the database, it will calculate a credit score(discrete value) for each customer. The calculated credit score helps the company and lenders to understand the credibility of a customer clearly. So they can simply take a decision whether they should lend money to a particular customer or not.
</p>
<b>The customer’s details could be:</b>

<ul>
  <i>Educational background details.</i>
  <li>Highest graduated degree.</li>
 <li>Cumulative grade points average (CGPA) or marks percentage.</li>
 <li>The reputation of the college.</li> 
 <li>Consistency in his lower degrees.</li>
<li>Whether to take the education loan or not.</li>
<li>Cleared education loan dues.</li>
</ul>

<ul>
  <i>Employment details</i>
  <li>Salary</li>
 <li>Year of experience</li>
 <li>Got any onsite opportunities</li> 
 <li>Average job change duration</li>
</ul>



<p>The company(XYZ) use’s these kinds of details to calculate credit score of a customer. The process of calculating the credit score from the customer’s details is expensive. To reduce the cost of predicting credit score, they realized that the customers with similar background details are getting a similar credit score.
<br>
So, they decided to use already available data of customers and predict the credit score using it by comparing it with similar data. These kinds of problems are handled by the k-nearest neighbor classifier for finding the similar kind of customers.
</p>
<b>K-nearest neighbor (Knn) algorithm pseudocode:</b>

<p>Let (Xi, Ci) where i = 1, 2……., n be data points. Xi denotes feature values & Ci denotes labels for Xi for each i.
  <br>
Assuming the number of classes as ‘c’<br>
Ci ∈ {1, 2, 3, ……, c} for all values of i
<br>
Let x be a point for which label is not known, and we would like to find the label class using k-nearest neighbor algorithms.
</p>
<b>Knn Algorithm Pseudocode:</b>

<p>Calculate “d(x, xi)” i =1, 2, ….., n; where d denotes the Euclidean distance between the points.
Arrange the calculated n Euclidean distances in non-decreasing order.
Let k be a +ve integer, take the first k distances from this sorted list.
<br>
Find those k-points corresponding to these k-distances.
Let ki denotes the number of points belonging to the ith class among k points i.e. k ≥ 0
If ki >kj ∀ i ≠ j then put x in class i.
</p>
    </div>



<div class="footer" >
  <p style="padding-top: 10">Designed and implemented by Naresh IT</p>
</div>



</body></html>



